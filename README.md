# Enhancing-Multi-modal-Cooperation-via-Sample-level-Modality-Valuation


Here is the official PyTorch implementation of ''*Enhancing Multi-modal Cooperation via Sample-level Modality Valuation*'', which aims to balance the uni-modal contribution during joint multi-modal training by re-sample strategy. Please refer to our [CVPR 2024 paper](#) for more details.

**Paper Title: "Enhancing Multi-modal Cooperation via Sample-level Modality Valuation"**

**Authors: [Yake Wei\*](https://echo0409.github.io/), Ruoxuan Feng, Zihe Wang and [Di Hu](https://dtaoo.github.io/index.html)**

**Accepted by: IEEE Conference on Computer Vision and Pattern Recognition(CVPR 2024)**

**[[arXiv](#)]** **[[Supplementary Material](#)]** 
